MODEL:
    TEMPERATURE: 0.2
    STREAM: True

    SERVICE: openai # [ ollama, openai, groq, gemini ]

    MODEL_ID: gpt-4o-mini

CONTEXTUAL_RAG:
    CHUNK_SIZE: 2048
    SERVICE: openai
    MODEL: "gpt-4o-mini"

    ORIGIN_RAG_COLLECTION_NAME: "original_rag"
    CONTEXTUAL_RAG_COLLECTION_NAME: "contextual_rag"

    QDRANT_URL: "http://localhost:6333"

    ELASTIC_SEARCH_URL: "http://localhost:9200"
    ELASTIC_SEARCH_INDEX_NAME: "contextual_rag"

    NUM_CHUNKS_TO_RECALL: 150

    SEMANTIC_WEIGHT: 0.8
    BM25_WEIGHT: 0.2

    TOP_N: 3

AGENT:
    TYPE: "openai" # [openai, react]
